# 流处理框架
## 什么是流处理
流处理是一种允许用户在接收到的数据后的短时间内快速查询连续数据流和检测条件的技术。它是大数据技术之一。 它被Apache Storm推广，现在有很多竞争者。而用户进行流处理的工具就是流处理框架
## 为什么需要流处理
大数据确立了从处理数据中得出的洞察力的价值。这种洞察力的价值并不相等。一些洞察力在事情发生后不久就有了更高的价值，而且这种价值会随着时间的推移而迅速减少。流处理针对这样的场景。流处理的关键优势在于它能够更快地提供洞察力，通常在毫秒到秒之间。
## 市面上主要的流处理框架
### 1 APACHE STORM:
Apache strom是一个免费的开源分布式实时计算系统。Storm使得可靠地处理无界数据流变得容易，用于实时处理就像Hadoop用于批处理一样。Storm很简单，可以与任何编程语言一起使用，而且使用起来很有趣！
Storm有许多用例：实时分析、在线机器学习、连续计算、分布式RPC、ETL等等。Storm很快：一个基准测试以每秒超过一百万个元组处理每个节点。它是可伸缩的，容错的，保证您的数据将被处理，并且易于设置和操作。
### 2 APACHE SAMZA:
Samza是一个流处理框架，具有以下特点：

简单的API：与大多数低级消息传递系统API不同，Samza提供了一个非常简单的基于回调的“流程消息”API，与MapReduce相当。

管理状态：Samza管理流处理器状态的快照和恢复。当重新启动处理器时，Samza将其状态恢复为一致的快照。Samza是用来处理大量的数据状态（每个分区千兆字节）。

容错：每当集群中的机器出现故障时，Samza都会使用YARN将任务透明地迁移到另一台机器。

持久性：Samza使用Kafka来保证消息按照它们被写入分区的顺序进行处理，并且不会丢失任何消息。

可伸缩性：Samza在每个层次上被划分和分布。卡夫卡提供有序的、可分割的、可重放的、容错的流。纱线为Samza容器的运行提供了分布式环境。

Pluggable：虽然Samza在Kafka和YARN中是开箱即用的，但是Samza提供了一个可插API，允许您与其他消息传递系统和执行环境一起运行Samza。
### 3 APACHE SPARK
Apache Spad是大规模数据处理的统一分析引擎，具有一下特点

速度：Apache Spark使用最先进的DAG调度器、查询优化器和物理执行引擎，实现了批处理数据和流数据的高性能。

易用性：Spark提供了80多个高级操作操作，使得构建并行应用程序变得容易。
并且可以与Scala、Python、R和SQL交互使用

Generality：Spark被很多库使用，包括SQL和数据框架、用于机器学习的MLlib、GraphX和Spark Streaming。可以在同一个应用程序中无缝地组合这些库。

Runs Everywhere：您可以使用Spark的独立集群模式，在EC2、Hadoop YARN、Mesos或Kubernetes上运行Spark。访问HDFS、Alluxio、Apache Cassandra、Apache HBase、Apache Hive以及数百个其他数据源中的数据。
### 4 APACHE KAFKA
#### Apache Kafka 是一个分布式流处理平台，具有以下3个关键功能：

1.Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.

2.Store streams of records in a fault-tolerant durable way.

3.Process streams of records as they occur.

#### Apache Kafka 的主要应用：

1.Building real-time streaming data pipelines that reliably get data between systems or applications

2.Building real-time streaming applications that transform or react to the streams of data

#### Apache Kafka 的4个核心API：

1.The Producer API allows an application to publish a stream of records to one or more Kafka topics.

2.The Consumer API allows an application to subscribe to one or more topics and process the stream of records produced to them.

3.The Streams API allows an application to act as a stream processor, consuming an input stream from one or more topics and producing an output stream to one or more output topics, effectively transforming the input streams to output streams.

4.The Connector API allows building and running reusable producers or consumers that connect Kafka topics to existing applications or data systems. For example, a connector to a relational database might capture every change to a table.

## Renfernce

1. APACHE STORM官网
2. APACHE SAMZA官网
3. APACHE SPARK官网
4. APACHE KAFKA官网


